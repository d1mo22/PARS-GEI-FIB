# CAIM - Cerca i Anàlisi d'Informació Massiva

<details open>
<summary>Català</summary>

## Sobre l'Assignatura

Aquest curs aborda els reptes d'organitzar i recuperar informació de col·leccions digitals massives. Els estudiants aprenen tècniques per ajudar els usuaris a trobar el que busquen eficientment dins de conjunts de dades a gran escala i entorns web.

### Temes Principals
- **Fonaments de Recuperació d'Informació**: Models d'indexació booleà, vectorial i semàntic
- **Implementació**: Fitxers invertits, compressió d'índexs, eines com Lucene/Elasticsearch
- **Avaluació del Rendiment**: Mesura de recall, precisió i retroalimentació de rellevància
- **Cerca Web**: Algorisme PageRank i arquitectura de crawlers web
- **Sistemes Escalables**: Enfocaments de computació distribuïda (MapReduce) per a conjunts de dades massius
- **Anàlisi de Xarxes**: Detecció de comunitats, nodes influents i propietats de grafs
- **Aplicacions Pràctiques**: Sistemes de recomanació, optimització de cerca, mineria de dades

### Objectius d'Aprenentatge
- Comprendre problemes de recuperació d'informació, particularment per a dades textuals
- Reconèixer com l'organització de la informació impacta l'efectivitat de la cerca
- Comprendre l'arquitectura web, crawlers i mecanismes de cerca
- Analitzar estructures de xarxes complexes i les seves característiques
- Aplicar tècniques d'extracció d'informació
- Implementar algorismes de recuperació i avaluar l'efectivitat del sistema

## Contingut de la Carpeta

| Carpeta | Descripció |
|---------|------------|
| `Theory/` | Diapositives de teoria (0-8: intro, models IR, implementació, similitud, web, bigdata, xarxes, recomanadors) |
| `Lab/` | Sessions de laboratori (notebooks Jupyter amb Elasticsearch, anàlisi de xarxes) |
| `Problems/` | Col·leccions de problemes |

</details>

<details>
<summary>Español</summary>

## Sobre la Asignatura

Este curso aborda los retos de organizar y recuperar información de colecciones digitales masivas. Los estudiantes aprenden técnicas para ayudar a los usuarios a encontrar lo que buscan eficientemente dentro de conjuntos de datos a gran escala y entornos web.

### Temas Principales
- **Fundamentos de Recuperación de Información**: Modelos de indexación booleano, vectorial y semántico
- **Implementación**: Archivos invertidos, compresión de índices, herramientas como Lucene/Elasticsearch
- **Evaluación del Rendimiento**: Medida de recall, precisión y retroalimentación de relevancia
- **Búsqueda Web**: Algoritmo PageRank y arquitectura de crawlers web
- **Sistemas Escalables**: Enfoques de computación distribuida (MapReduce) para conjuntos de datos masivos
- **Análisis de Redes**: Detección de comunidades, nodos influyentes y propiedades de grafos
- **Aplicaciones Prácticas**: Sistemas de recomendación, optimización de búsqueda, minería de datos

### Objetivos de Aprendizaje
- Comprender problemas de recuperación de información, particularmente para datos textuales
- Reconocer cómo la organización de la información impacta la efectividad de la búsqueda
- Comprender la arquitectura web, crawlers y mecanismos de búsqueda
- Analizar estructuras de redes complejas y sus características
- Aplicar técnicas de extracción de información
- Implementar algoritmos de recuperación y evaluar la efectividad del sistema

## Contenido de la Carpeta

| Carpeta | Descripción |
|---------|-------------|
| `Theory/` | Diapositivas de teoría (0-8: intro, modelos IR, implementación, similitud, web, bigdata, redes, recomendadores) |
| `Lab/` | Sesiones de laboratorio (notebooks Jupyter con Elasticsearch, análisis de redes) |
| `Problems/` | Colecciones de problemas |

</details>

<details>
<summary>English</summary>

## About the Subject

This course addresses the challenges of organizing and retrieving information from massive digital collections. Students learn techniques to help users find what they seek efficiently within large-scale datasets and web environments.

### Main Topics
- **Information Retrieval Fundamentals**: Boolean, vector, and semantic indexing models
- **Implementation**: Inverted files, index compression, tools like Lucene/Elasticsearch
- **Performance Evaluation**: Measuring recall, precision, and relevance feedback
- **Web Search**: PageRank algorithm and web crawler architecture
- **Scalable Systems**: Distributed computing approaches (MapReduce) for massive datasets
- **Network Analysis**: Detecting communities, influential nodes, and graph properties
- **Practical Applications**: Recommendation systems, search optimization, data mining

### Learning Objectives
- Understand information retrieval problems, particularly for textual data
- Recognize how information organization impacts search effectiveness
- Comprehend web architecture, crawlers, and search mechanisms
- Analyze complex network structures and their characteristics
- Apply information extraction techniques
- Implement recovery algorithms and assess system effectiveness

## Folder Contents

| Folder | Description |
|--------|-------------|
| `Theory/` | Theory slides (0-8: intro, IR models, implementation, similarity, web, bigdata, networks, recommenders) |
| `Lab/` | Laboratory sessions (Jupyter notebooks with Elasticsearch, network analysis) |
| `Problems/` | Problem sets |

</details>
