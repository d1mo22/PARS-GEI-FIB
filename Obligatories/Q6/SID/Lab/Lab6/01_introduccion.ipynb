{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c81d9ce31ea3596",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Lab: Aprendizaje por refuerzo (I)\n",
    "# 1 - Gymnasium y entorno FrozenLake-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f11c45d63e7e7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "En esta sesión vamos a ver Gymnasium, una librería de referencia para probar algoritmos de aprendizaje por refuerzo que incluye algunos entornos y además define una interfaz común para integrar entornos nuevos basada en el bucle del agente inteligente que ya hemos visto en clase de teoría."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145886c0d320e54d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Configuración y dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effb511a40e72b79",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Declaración de constantes\n",
    "SLIPPERY = False\n",
    "NUM_EPISODES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b71fa5939d6f17",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting cloudpickle>=1.2.0 (from gymnasium)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/david/anaconda3/envs/learn/lib/python3.13/site-packages (from gymnasium) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Downloading pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.10.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.56.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading kiwisolver-1.4.8-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/david/anaconda3/envs/learn/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pillow-11.1.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/david/anaconda3/envs/learn/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/david/anaconda3/envs/learn/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading numpy-2.2.4-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pygame-2.6.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading matplotlib-3.10.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp313-cp313-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, farama-notifications, tzdata, pyparsing, pygame, pillow, numpy, kiwisolver, fonttools, cycler, cloudpickle, pandas, gymnasium, contourpy, matplotlib, seaborn\n",
      "Successfully installed cloudpickle-3.1.1 contourpy-1.3.1 cycler-0.12.1 farama-notifications-0.0.4 fonttools-4.56.0 gymnasium-1.1.1 kiwisolver-1.4.8 matplotlib-3.10.1 numpy-2.2.4 pandas-2.2.3 pillow-11.1.0 pygame-2.6.1 pyparsing-3.2.1 pytz-2025.1 seaborn-0.13.2 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium seaborn numpy pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa0e018a545e861",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752d95c1d7ea7af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Entorno FrozenLake-v1\n",
    "\n",
    "Vamos a hacer pruebas con el entorno FrozenLake-v1. En el enlace [https://gymnasium.farama.org/environments/toy_text/frozen_lake/](https://gymnasium.farama.org/environments/toy_text/frozen_lake/) tenéis una descripción detallada del entorno. Dedicadle unos minutos a leerlo con calma para poder entender el efecto de los diferentes algoritmos sobre el proceso de aprendizaje.\n",
    "\n",
    "Lo primero que vamos a hacer es ejecutar el entorno con una política totalmente aleatoria. Cuando ejecutéis la siguiente celda aparecerá una ventana con el entorno. Puede que se oculte detrás de las demás ventanas por lo que quizá tendréis que buscarla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab71258821f20df4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last state  = 12\n",
      "reward =      0.0\n",
      "terminated =  True\n",
      "truncated  =  False\n",
      "time steps =  23\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make(\"FrozenLake-v1\", desc=None, map_name=\"4x4\", render_mode=\"human\", is_slippery=False) \n",
    "env.reset()\n",
    "env.render()\n",
    "is_done = False\n",
    "t = 0\n",
    "\n",
    "while not is_done:\n",
    "   action = env.action_space.sample()\n",
    "   state, reward, is_done, truncated, _ = env.step(action)\n",
    "   env.render()\n",
    "   t +=1\n",
    "        \n",
    "print(\"\\nlast state  =\", state)\n",
    "print(\"reward =     \", reward)\n",
    "print(\"terminated = \", is_done)\n",
    "print(\"truncated  = \", truncated)\n",
    "print(\"time steps = \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359f29eaceeb1e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Como vemos, con la función `step()` del entorno ejecutamos una acción. En este caso, con la llamada a `env.action_space.sample()` estamos obteniendo una acción aleatoria del espacio de acciones (el elemento `A` de la tupla del MDP). Como resultado de ejecutar la acción, recibimos:\n",
    "\n",
    "* `state`: el nuevo estado en el que está el agente.\n",
    "* `reward`: la recompensa obtenida al haber llegado al nuevo estado desde el anterior mediante la acción ejecutada.\n",
    "* `terminated`: un booleano que representa si hemos llegado a un estado final.\n",
    "* `truncated`: un booleano que nos dice si el entorno se ha detenido de manera inesperada (e.g. por un hipotético límite de tiempo).\n",
    "* `info`: una estructura con metadatos y monitorización, que no usaremos en esta sesión.\n",
    "\n",
    "Vamos ahora a encapsular esta política en una clase que representará nuestro agente y que iremos evolucionando y modificando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a1a79b2babf4db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def select_action(self):\n",
    "        return self.env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f44a73fb38cf0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Vamos a definir también el entorno que vamos a usar en el resto de ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd7c1b1e59404c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", desc=None, map_name=\"4x4\", render_mode=\"human\", is_slippery=SLIPPERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d034aceedeefd69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Replicamos ahora el resultado de antes, pero ahora con la clase RandomAgent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375043607cf1676",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render()\n",
    "is_done = False\n",
    "t = 0\n",
    "agent = RandomAgent(env)\n",
    "while not is_done:\n",
    "   action = agent.select_action()\n",
    "   state, reward, is_done, truncated, _ = env.step(action)\n",
    "   env.render()\n",
    "   t += 1\n",
    "        \n",
    "print(\"\\nlast state  =\", state)\n",
    "print(\"reward =     \", reward)\n",
    "print(\"terminated = \", is_done)\n",
    "print(\"truncated  = \", truncated)\n",
    "print(\"time steps = \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62551a75c6bdcd26",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Obviamente parece que el agente no va a resolver esta tarea (a menos que hayáis tenido muchísima suerte). Vamos a realizar unas cuantas ejecuciones para sacar resultados empíricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782dacd1b2472a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def test_episode(agent, env):\n",
    "    env.reset()\n",
    "    is_done = False\n",
    "\n",
    "    while not is_done:\n",
    "        action = agent.select_action()\n",
    "        state, reward, is_done, truncated, info = env.step(action)\n",
    "    return state, reward, is_done, truncated, info\n",
    "\n",
    "agent = RandomAgent(env)\n",
    "\n",
    "solved = 0\n",
    "rewards = []\n",
    "for episode in range(50):\n",
    "    state, reward, is_done, truncated, _ = test_episode(agent, env)\n",
    "    rewards.append(reward)\n",
    "    if state == 15:\n",
    "        solved += 1\n",
    "\n",
    "print(\"Solved\", solved, \"times (\", solved * 2, \"%)\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9912f3e37304f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Episode': range(1, len(rewards) + 1), 'Reward': rewards})\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Episode', y='Reward', data=data)\n",
    "\n",
    "plt.title('Rewards Over Episodes')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220498382490180",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "En el siguiente notebook vamos a comenzar a aplicar algoritmos más fiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bd220032c1ba1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
