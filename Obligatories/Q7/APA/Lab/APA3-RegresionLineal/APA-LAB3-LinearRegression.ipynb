{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf15854f",
   "metadata": {},
   "source": [
    "&#x1f12f; Raquel Pérez & Javier Bejar - APA/GEI/FIB/UPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bf4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to upgrade packages\n",
    "# !pip3 install pandas --upgrade --quiet\n",
    "# !pip3 install numpy  --upgrade --quiet\n",
    "# !pip3 install scipy --upgrade --quiet\n",
    "# !pip3 install statsmodels  --upgrade --quiet\n",
    "# !pip3 install seaborn  --upgrade --quiet\n",
    "# !pip3 install matplotlib  --upgrade --quiet\n",
    "# !pip3 install scikit-learn  --upgrade  --quiet\n",
    "# !pip install scikit-optimize  --quiet\n",
    "# !pip install -U --quiet yellowbrick\n",
    "!pip install apafib --upgrade  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf134081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "init_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71b19f",
   "metadata": {},
   "source": [
    "# APA - Laboratorio - Sesión 3\n",
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split,  KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import set_config\n",
    "\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "from yellowbrick.regressor.alphas import alphas\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set()\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b2c4f",
   "metadata": {},
   "source": [
    "## SECCIÓN 1: Los datos\n",
    "\n",
    "En esta sesión de laboratorio vamos a predecir la esperanza de vida de diferentes países durante diferentes años dados diferentes marcadores socioeconómicos.\n",
    "\n",
    "Como puede notar, este conjunto de datos tiene un componente temporal (la esperanza de vida en un país un año puede tener una correlación con los años anteriores y posteriores). Normalmente, este componente temporal debe tenerse en cuenta (rompe la suposición de iid, por ejemplo), sin embargo, por simplicidad, lo ignoraremos. El tratamiento del componente temporal está fuera del alcance del curso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "try:\n",
    "    from apafib import load_life_expectancy\n",
    "    life_expectancy_data = load_life_expectancy()\n",
    "except:\n",
    "    life_expectancy_data = pd.read_csv('Life_Expectancy_Data.csv')\n",
    "\n",
    "# remove spaces and symbols to avoid problems with statsmodel GLM\n",
    "life_expectancy_data.columns = [c.lower().strip().replace(' ','_').replace('/','_').replace('-','_') \n",
    "                                for c in life_expectancy_data.columns] \n",
    "\n",
    "# change the type of categorical variables into category\n",
    "categorical_columns = list(life_expectancy_data.dtypes[life_expectancy_data.dtypes == 'O'].index.values)\n",
    "for column in categorical_columns:\n",
    "    life_expectancy_data[column] = life_expectancy_data[column].astype('category')\n",
    "\n",
    "# peek into the data\n",
    "life_expectancy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acc3f1",
   "metadata": {},
   "source": [
    "Siempre es una buena idea hacer una pequeña exploración de los datos. Los datos reales necesitan procesamiento previo y es importante comprender su conjunto de datos para poder tomar buenas decisiones de diseño.\n",
    "\n",
    "Nuestro conjunto de datos tiene 2938 muestras y 21 variables predictivas. Nuestro objetivo es `life_expectancy`.\n",
    "\n",
    "Vamos a hacer una visualización rápida de los datos. En esta visualización usamos histogramas para mostrar la distribución de las variables numéricas y diagramas de barras para las categóricas.\n",
    "\n",
    "Con este tipo de visualizaciones fáciles, podemos ver mucha información relevante sobre nuestros datos, como si tenemos nuestros valores o si alguna variable se ha codificado incorrectamente, o si \"parece\" lo suficientemente gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271788d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7,3,figsize=(15,30))\n",
    "\n",
    "# We will not plot country because it has too many categories.\n",
    "for i, c in enumerate(life_expectancy_data.columns[1:]):\n",
    "    ax = axes.reshape(-1)[i]\n",
    "    if life_expectancy_data[c].dtype.kind == 'O':\n",
    "        a = sns.countplot(x=c,data=life_expectancy_data,ax=ax)\n",
    "    else:\n",
    "        b = sns.histplot(x=c,data=life_expectancy_data,ax=ax)\n",
    "    t = ax.set_title(c)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6600838",
   "metadata": {},
   "source": [
    "Si no podéis representar una variable categórica de manera efectiva porque tiene demasiadas categorías, podéis verificarla con la función `value_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(life_expectancy_data['country'].unique())\n",
    "life_expectancy_data['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff60035",
   "metadata": {},
   "source": [
    "Otra forma de visualizar cada variable (numérica) es usar la función de histograma de `pandas` en todo el marco de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb173ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy_data.hist(figsize=(26,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a074b1",
   "metadata": {},
   "source": [
    "## Valores perdidos\n",
    "\n",
    "Ahora que sabemos cómo se ven nuestros datos, es una buena idea verificar cuántos valores perdidos tenemos en cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f036cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad078ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "life_expectancy_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0b604",
   "metadata": {},
   "source": [
    "Podemos utilizar toda esta información para diseñar una metodología de preprocesamiento eficaz y elegir un modelo adecuado adaptado a nuestros datos. Para mostrar cuán importante es esto, haremos dos preprocesamientos diferentes:\n",
    "\n",
    "* **Preprocesamiento genérico**: simplemente transforma los datos en algo que un modelo puede procesar sin dar errores. Ignorando por completo las peculiaridades del conjunto de datos.\n",
    "\n",
    "* **Preprocesamiento Específico**: Preprocesamiento adaptado a los modelos que estaremos utilizando y las particularidades de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0a6ad",
   "metadata": {},
   "source": [
    "### Protocolo de muestreo y prueba\n",
    "\n",
    "Usaremos dos particiones de datos (entrenamiento y prueba) con validación cruzada sobre la partición de entrenamiento para decidir los hiperparámetros. \n",
    "\n",
    "Explicaremos en detalle la validación cruzada en la sección 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = life_expectancy_data.loc[:,life_expectancy_data.columns != 'life_expectancy']\n",
    "y = life_expectancy_data['life_expectancy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07e28d",
   "metadata": {},
   "source": [
    "## SECCIÓN 3: Regresión lineal (con mínimo preprocesamiento de los datos)\n",
    "\n",
    "Esta es la sesión de laboratorio de Regresión Lineal. Por esta razón, utilizaremos los modelos de regresión lineal, regresión LASSO y regresión RIDGE. Estos modelos no son compatibles con valores faltantes, ni variables categóricas. Por lo tanto, lo mínimo absoluto que debemos hacer con nuestros datos es eliminar muestras con faltantes y variables categóricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_preprocessing(X, y):\n",
    "    print('Tamaño original:{}'.format(X.shape))\n",
    "    categorical_columns = X.dtypes[X.dtypes == 'category'].index.values\n",
    "    # Eliminamos variables categoricas\n",
    "    X=X.drop(columns=categorical_columns)\n",
    "    print('Eliminadas: {}'.format(categorical_columns))\n",
    "    # Eliminamos valores perdidos\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('Nuevo tamaño:{}'.format(X.shape))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a810e2",
   "metadata": {},
   "source": [
    "Aplicaremos por separado nuestro preprocesamiento a nuestras particiones de entrenamiento y prueba, fijaos que no hacemos nada en los datos de test que dependa de lo que hemos hecho en los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aed16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = minimum_preprocessing(X_train,y_train)\n",
    "X_test, y_test = minimum_preprocessing(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12252ec",
   "metadata": {},
   "source": [
    "### Regresión lineal\n",
    "\n",
    "Pequeño recordatorio de como funciona la regresión lineal: \n",
    "\n",
    "Modelamos nuestra función de regresión como\n",
    "\n",
    " $y = f(x) + \\epsilon = w^\\top x + \\epsilon$\n",
    " \n",
    " dónde:\n",
    " * $y$ es nuestro objetivo.\n",
    " * $w$ son los pesos que calcularemos.\n",
    " * $x$ son nuestras muestras.\n",
    " * $\\epsilon$ es el ruido de las muestras.\n",
    "\n",
    "Si asumimos que el ruido es gaussiano, resolver este problema equivale a minimizar el error cuadrático medio de esta función.\n",
    "\n",
    "$\\min_w || y-Xw ||^2$\n",
    "\n",
    "Veremos dos implementaciones diferentes de regresión lineal. La de statsmodels y la de scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869c10a",
   "metadata": {},
   "source": [
    "#### Scikit-learn linear regression\n",
    "\n",
    "Los modelos scikit-klearn son realmente fáciles de usar. Todos están implementados en clases con la misma estructura, por lo que al conocer uno, se conocen todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893777d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo LinearRegression \n",
    "lr = LinearRegression();\n",
    "\n",
    "# Ajustamos con los datos de entrenamiento con el método fit\n",
    "lr.fit(X_train,y_train);\n",
    "\n",
    "# Predecimos con el método predict \n",
    "y_pred = lr.predict(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cac369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = lr.coef_\n",
    "intercept = lr.intercept_\n",
    "# Podemos acceder a información del modelo, como los pesos.\n",
    "print('Coeficientes: \\n', weights[:10])\n",
    "print('Interceptor: \\n', intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4add2",
   "metadata": {},
   "source": [
    "\n",
    "#### Statsmodels linear regression\n",
    "*La regresión lineal de Statsmodels* es un poco más difícil de usar pero genera una gran cantidad de datos estadísticos que pueden ser útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression se llama ordinary least squares (OLS) en statsmodels\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990719b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Además de los pesos, statsmodels devuelve el intervalo de confianza del 95 % de estos pesos ([0,025 0,975]), el error estándar de los pesos (std err) y el valor p (P>|z|). Si el valor de p es menor a un umbral (generalmente 0.05), podemos decir que la variable es relevante para predecir el objetivo.\n",
    "\n",
    "Los residuos (la diferencia entre el valor objetivo real y el valor objetivo previsto) son:\n",
    "\n",
    " $(t_n - y(x_n; w)), n = 1,\\dots N$\n",
    "\n",
    "Si representamos los residuos de los datos de entrenamiento obtenemos la siguiente distribución:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb448894",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(result.resid,bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf627f",
   "metadata": {},
   "source": [
    "Esperamos que este gráfico parezca gaussiano, ya que es nuestra suposición inicial (error gaussiano). Por esta razón, esta gráfica es un indicador directo de la validez del modelo.\n",
    "\n",
    "Otra gráfica que podemos usar para validar nuestro modelo es un QQ-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "stats.probplot(result.resid, plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387de7b",
   "metadata": {},
   "source": [
    "Podemos obtener un gráfico de los residuos del entrenamiento y el test con el _qqplot_ o el _histograma_ con la librería `yellowbrick`.\n",
    "\n",
    "El grafico de los residuos nos permitira mejor si hay cosas extrañas en su distribucion, como en este caso. A pesar de que la el histograma de los residuos parezca gausiana, hay cierta discordancia con los cuantiles teoricos y podemos ver que los residuos se comportan de manera diferente dependiendo del valor que se predice. Tambien afecta que haya un desbalance entre los valores bajos y altos en los datos que tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d041f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import residuals_plot\n",
    "plt.figure(figsize=(12,8));\n",
    "viz = residuals_plot(lr, X_train, y_train, X_test, y_test, is_fitted=True, qqplot=True, hist=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877145c6",
   "metadata": {},
   "source": [
    "También podemos representar las predicciones respecto a los valores reales y ver cuanto se desvían de la predicción ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb855420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import prediction_error\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "visualizer = prediction_error(lr, X_test, y_test, is_fitted=True)\n",
    "0;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc056c7f",
   "metadata": {},
   "source": [
    "## SECCIÓN 3: Metricas\n",
    "\n",
    "Hay métricas alternativas que podemos usar para medir el rendimiento de un modelo de regresión.\n",
    "Repasaremos las más comunes sobre las predicciones de datos de entrenamiento.\n",
    "\n",
    "**Mean Squared Error (MSE)** \n",
    "\n",
    "El mejor resultado posible sería un MSE de 0, lo que significaría una predicción perfecta.\n",
    "\n",
    "$MSE(t,y) = \\frac{1}{N} \\sum_{i=1}^N (t - y(x;w))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0]\n",
    "\n",
    "# usando statsmodel\n",
    "prediction = result.predict(sm.add_constant(X_train))\n",
    "mean_square_error = np.sum((y_train - prediction)**2)/N\n",
    "\n",
    "# También se puede calcular con su implementacion en scikit-learn\n",
    "mean_square_error_sk = mean_squared_error(y_train, prediction)\n",
    "\n",
    "mean_square_error, mean_square_error_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845973a6",
   "metadata": {},
   "source": [
    "Este número depende de la magnitud de la variable objetivo, por lo que no podemos saber si es bueno o malo directamente. Es una muy buena práctica normalizarlo dividiendo por la varianza no sesgada de la muestra de la variable objetivo. De esta manera obtenemos el\n",
    "\n",
    "**Normalized Mean Squared Error**\n",
    "\n",
    "Nuevamente, el mejor resultado posible sería 0, por la misma razón.\n",
    "\n",
    "$norm\\_MSE(t,y) = \\frac {MSE(t,y)}{\\sigma^2(t)} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mse = np.sum((y_train - prediction)**2)/((N)*np.var(y_train))\n",
    "\n",
    "# Se puede usar la implementacion de R^2 de para calcular este valor\n",
    "norm_mse_sk = 1-r2_score(y_train,prediction)\n",
    "\n",
    "norm_mse, norm_mse_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7097613",
   "metadata": {},
   "source": [
    "Si dividimos el error cuadrático medio por la varianza de los objetivos t,\n",
    " obtenemos la proporción de la variabilidad del objetivo que NO es explicada por el modelo\n",
    "\n",
    " Un modelo con 'norm.mse' igual a 1 es tan bueno como el mejor modelo constante\n",
    " (es decir, el modelo que siempre da como respuesta el promedio del objetivo)\n",
    "\n",
    " los modelos con 'norm.mse' por encima de 0.5 son regulares, mas alla de 0.7 empiezan a ser bastante malos\n",
    "\n",
    " los modelos con 'norm.mse' por debajo de 0.2 son bastante buenos\n",
    "\n",
    "\n",
    "**R-squared (R^2)**\n",
    "\n",
    "El R^2 (generalmente utilizado por los estadísticos) se obtiene restando esta cantidad de uno; es decir, la proporción de la variabilidad objetivo que explica el modelo; en este caso alcanza ~80%\n",
    "\n",
    "Esta métrica suele mostrarse entre 0 y 1 o en porcentaje, pero hay que tener en cuenta que no esta limitada por abajo, una regresión puede ser arbitrariamente mala (valores negativos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_squared = (1 - norm_mse)\n",
    "\n",
    "# También se puede usar la implementacion de scikit-learn\n",
    "R_squared_sk = r2_score(y_train,prediction) \n",
    "\n",
    "R_squared, R_squared_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d9796",
   "metadata": {},
   "source": [
    "**Mean Absolute Error (MAE)**\n",
    "\n",
    "El mejor resultado posible también sería un MAE de 0, lo que significaría una predicción perfecta.\n",
    "\n",
    "$MAE(t,y) = \\frac{1}{N} \\sum_{i=1}^N |t - y(x;w)|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae =  np.sum(np.abs(y_train - prediction))/N\n",
    "\n",
    "# Se puede usar la implementacion de MAE de para calcular este valor\n",
    "mae_sk = mean_absolute_error(y_train,prediction)\n",
    "\n",
    "mae, mae_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f87eb",
   "metadata": {},
   "source": [
    "Hemos visto aquí que el modelo tiene buenos resultados con los datos de entrenamiento, pero eso no significa que nuestro modelo sea un buen predictor.\n",
    "Para tener una valoración numérica de su capacidad predictiva tenemos varias opciones:\n",
    "* Obtenga nuevos datos (¡no es posible aquí!)\n",
    "* Utilizar LOOCV.\n",
    "* Predecir sobre una partición de validación específica y calcular las medidas pertinentes.\n",
    "* Utilizar la validación cruzada.\n",
    "\n",
    "No hemos guardado una partición específica para obtener métricas de validación y tenemos demasiadas muestras (1123 en proceso) para hacer LOOCV rápido. Por esta razón haremos validación cruzada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b509e",
   "metadata": {},
   "source": [
    "## SECCIÓN 4: Validación cruzada (Cross Validation)\n",
    "\n",
    "Necesitamos saber qué tan bueno es nuestro modelo. No podemos usar el conjunto de datos de entrenamiento para esto porque podría dar resultados artificialmente buenos. No podemos usar la partición de prueba porque necesitaremos comparar estos resultados con los obtenidos en otros modelos. Queremos usar el conjunto de prueba solo al final, para que pueda simular la ejecución del modelo con datos nuevos. De esta manera podemos obtener un error de generalización lo más cercano posible al error que obtendríamos usando el modelo con datos completamente nuevos.\n",
    "\n",
    "Como no podemos usar ni el entrenamiento ni el conjunto de prueba para evaluar el modelo, usaremos **Validación cruzada** para calcular nuestras métricas, usaremos estas métricas comparar modelos y tomar cualquier decisión de diseño.\n",
    "\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8940773d",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Nota: Esta es la implementacion de la validacion cruzada desde cero, para que veais que es lo que se hace, pero scikit-learn ya la tiene implementada y es la que usaremos </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_metrics = pd.DataFrame(columns=['MSE', 'norm_MSE', 'R2'])\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "i=1\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Split {}: \\n\\tTest Folds: [{}] \\n\\tTrain Folds {}'.format(i, i, [j for j in range(1,6) if j != i]));\n",
    "    \n",
    "    x_train_fold = X_train.values[train_index]\n",
    "    y_train_fold = y_train.values[train_index]\n",
    "    x_test_fold = X_train.values[test_index,:]\n",
    "    y_test_fold = y_train.values[test_index]\n",
    "    \n",
    "    lr = LinearRegression().fit(x_train_fold,y_train_fold)\n",
    "    y_pred_fold = lr.predict(x_test_fold)\n",
    "    fold_mse =mean_squared_error(y_test_fold, y_pred_fold)\n",
    "    fold_nmse =  1-r2_score(y_test_fold, y_pred_fold)\n",
    "    fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "    print(f'\\tMSE: {fold_mse:3.3f} NMSE: {fold_nmse:3.3f} R2: {fold_r2:3.3f}')\n",
    "\n",
    "    cross_val_metrics.loc[f'Fold {i}', :] = [fold_mse,fold_nmse, fold_r2]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d622e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_metrics.loc['Mean',:] = cross_val_metrics.mean()\n",
    "cross_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb78c1e",
   "metadata": {},
   "source": [
    "Usaremos la media de las particiones como nuestra métrica. También podemos hacer esto usando el método sklearn `cros_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train);\n",
    "folds_r2 = cross_val_score(lr, X_train,y_train, cv=5, scoring='r2')\n",
    "lr_r2 = np.mean(folds_r2) \n",
    "folds_r2, lr_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac732883",
   "metadata": {},
   "source": [
    "## SECCIÓN 5: Regresión lineal regularizada: Ridge and LASSO\n",
    "\n",
    "Ahora que tenemos una forma de evaluar el rendimiento de nuestro modelo, veamos si mejora agregando regularización. \n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "Esta vez vamos a minimizar la siguiente función:\n",
    "\n",
    "$\\min_w (|| y - Xw ||^2 + \\lambda \\cdot ||w||^2_2)$\n",
    "\n",
    "El último término penaliza que los pesos sean demasiado grandes (en magnitud).\n",
    "El hiperparámetro $\\lambda$ controlará cuánto los estamos penalizando.\n",
    "\n",
    "Lambda no se calcula sobre el proceso de entrenamiento como los pesos, es un *hiperparámetro*.\n",
    "Entonces ahora la pregunta es: ¿Cómo podemos encontrar la mejor $\\lambda$ para nuestro conjunto de datos?\n",
    "\n",
    "Hemos dicho en la sección anterior que podemos usar métricas de validación cruzada para comparar el rendimiento predictivo de diferentes modelos. Podemos hacer lo mismo para comparar el mismo modelo con diferentes hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363227ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cross_val_metrics = pd.DataFrame(columns=['mean MSE', 'mean norm_MSE', 'mean R2'])\n",
    "lambdas = [1e-4,1e-3,1e-2,0.1, 0.5,1,5,10,50,100]\n",
    "# Calculamos las metricas de validación cruzada para cada lambda\n",
    "for lambda_val in lambdas:\n",
    "    kf = KFold(n_splits=5)\n",
    "    i=1\n",
    "    cv_mse = []\n",
    "    cv_nmse = []\n",
    "    cv_r2 = []\n",
    "    # Calculamos la metrica para cada particion y hacemos la media\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train_fold = X_train.values[train_index]\n",
    "        y_train_fold = y_train.values[train_index]\n",
    "        x_test_fold = X_train.values[test_index,:]\n",
    "        y_test_fold = y_train.values[test_index]\n",
    "\n",
    "        lr = Ridge(alpha=lambda_val).fit(x_train_fold,y_train_fold)\n",
    "        y_pred_fold = lr.predict(x_test_fold)\n",
    "        fold_mse =mean_squared_error(y_test_fold, y_pred_fold)\n",
    "        fold_nmse =  1-r2_score(y_test_fold, y_pred_fold)\n",
    "        fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "        cv_mse.append(fold_mse)\n",
    "        cv_nmse.append(fold_nmse)\n",
    "        cv_r2.append(fold_r2)\n",
    "    ridge_cross_val_metrics.loc[f'Lambda={lambda_val}',:] = [np.mean(cv_mse),np.mean(cv_nmse),np.mean(cv_r2)]\n",
    "    \n",
    "ridge_cross_val_metrics.sort_values(by='mean R2',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9858a56",
   "metadata": {},
   "source": [
    "Otra manera es usar la implementacion de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8448b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "\n",
    "print(f'Best lambda: {ridge_cv.alpha_} R2 score: {ridge_cv.best_score_:3.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b29ed8",
   "metadata": {},
   "source": [
    "Ridge Regression no parece mejorar los resultados de la regresión lineal. Comprobemos si LASSO funciona mejor.\n",
    "\n",
    "### Regresión LASSO\n",
    "\n",
    "Esta vez penalizamos los pesos usando su norma L1.\n",
    "\n",
    "\n",
    "$\\min_w (|| y - Xw ||^2 + \\lambda * |w|)$\n",
    "\n",
    "Usaremos el método CV de scikit-learn para calcular la mejor $\\lambda$ directamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "\n",
    "lasso_r2 =  np.mean(cross_val_score(lasso_cv, X_train,y_train))\n",
    "\n",
    "print('Best lambda:', lasso_cv.alpha_, 'R2 score:',lasso_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777d2cc",
   "metadata": {},
   "source": [
    "Estos son los resultados finales, fijaos que nosotros usaremos la medida de la calidad del modelo siempre de la validacion cruzada. El error sobre los datos de entrenamiento sera por lo general mas optimista y no sera fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc10c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_results = pd.DataFrame({'lr':lr_r2, 'ridge_cv':ridge_cv.best_score_, 'lasso_cv':lasso_r2},index=['CV R2'])\n",
    "\n",
    "r2_results.loc['Test R2', :] =[r2_score(y_test,lr.predict(X_test)),\n",
    "                                r2_score(y_test,ridge_cv.predict(X_test)),\n",
    "                                r2_score(y_test,lasso_cv.predict(X_test))]\n",
    "r2_results.loc['lambda','lr']=0\n",
    "r2_results.loc['lambda','ridge_cv']=ridge_cv.alpha_\n",
    "r2_results.loc['lambda','lasso_cv']=lasso_cv.alpha_\n",
    "r2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3d13c",
   "metadata": {},
   "source": [
    "## SECCIÓN 6: Entender los modelos es importante &#x261d;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ab02b",
   "metadata": {},
   "source": [
    "Tampoco podemos ver una gran mejora con LASSO.\n",
    "\n",
    "Entonces, ¿por qué la regularización no funciona cuando se supone que debe dar mejores modelos?\n",
    "\n",
    "Comprobemos los pesos de nuestros tres modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6faa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = pd.DataFrame({'lr':lr.coef_, 'ridge_cv':ridge_cv.coef_, 'lasso_cv':lasso_cv.coef_},index=X_train.columns)\n",
    "weights.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351059c",
   "metadata": {},
   "source": [
    "Visualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,  ax = plt.subplots( figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['lr'],:].abs(),annot=True, linewidths=.5,ax=ax,cbar=False,xticklabels=False);\n",
    "\n",
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['ridge_cv'],:].abs(),annot=True, linewidths=.5,cbar=False,xticklabels=False);\n",
    "\n",
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['lasso_cv'],:].abs(),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f50c9f",
   "metadata": {},
   "source": [
    "Podemos ver algunos patrones extraños en nuestros pesos, en los tres modelos podemos ver una amplia gama de valores. Tanto LASSO como Ridge tienen casi el mismo peso.\n",
    "\n",
    "Si comparamos los pesos con los valores medios de nuestras variables, podemos ver que la regresión lineal está tratando de equilibrar los rangos de las variables. Probablemente por eso nuestros modelos regularizados no funcionan tan bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(X_train.mean().to_frame().T.rename(index={0:'Mean'}),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c2771",
   "metadata": {},
   "source": [
    "Vamos a arreglar esto escalando nuestros datos. De esta forma, todas las variables tendrán el mismo rango y aprovecharemos mejor nuestros modelos.\n",
    "\n",
    "<span style=\"color:red\">**Tened en cuenta que la forma de hacer el procesamiento previo para los datos del test se obtiene del que hemos hecho a los datos de entrenamiento. Esencialmente, esto es para evitar cualquier tipo de sesgo entre entrenamiento y test**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_preprocessing(X, y, scaler=None):\n",
    "    print('Tamaño Original:{}'.format(X.shape))\n",
    "    categorical_columns = X.dtypes[X.dtypes == 'category'].index.values\n",
    "    \n",
    "    # Escalamos las variables numericas\n",
    "    numerical_columns = [c for c in X.columns if c not in categorical_columns]\n",
    "    if scaler is None: \n",
    "        # Generamos el scaler cuando los datos son los de entrenamiento\n",
    "        scaler = MinMaxScaler()\n",
    "        X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "    else: \n",
    "        X[numerical_columns] = scaler.transform(X[numerical_columns])\n",
    "    \n",
    "    # Eliminamos las variables categoricas\n",
    "    X=X.drop(columns=categorical_columns)\n",
    "    print('Eliminadas: {}'.format(categorical_columns))\n",
    "    # Eliminamos los valores perdidos\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('New shape:{}'.format(X.shape))\n",
    "    return X, y, scaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, y_train, scaler = scaling_preprocessing(X_train,y_train)\n",
    "X_test, y_test, _ = scaling_preprocessing(X_test,y_test,scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e0347",
   "metadata": {},
   "source": [
    "Ahora nuestras variables tienen rangos más razonables. Veamos cómo afecta esto a los pesos y el rendimiento de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730b017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(X_train.mean().to_frame().T.rename(index={0:'Mean'}),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48951aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scaled = LinearRegression().fit(X_train,y_train)\n",
    "r2_lr_scaled = np.mean(cross_val_score(lr_scaled, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "ridge_cv_scaled =RidgeCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "r2_ridge_scaled = np.mean(cross_val_score(ridge_cv_scaled, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "\n",
    "lasso_cv_scaled =LassoCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "r2_lasso_scaled = np.mean(cross_val_score(lasso_cv_scaled, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "weights = pd.DataFrame({'lr scaled':lr_scaled.coef_, 'ridge_cv scaled':ridge_cv_scaled.coef_, 'lasso_cv scaled':lasso_cv_scaled.coef_},index=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd853b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,  ax = plt.subplots( figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['lr scaled'],:].abs(),annot=True, linewidths=.5,ax=ax,cbar=False,xticklabels=False);\n",
    "\n",
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['ridge_cv scaled'],:].abs(),annot=True, linewidths=.5,cbar=False,xticklabels=False);\n",
    "\n",
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['lasso_cv scaled'],:].abs(),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d830a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_results = pd.DataFrame({'lr':r2_lr_scaled, 'ridge_cv':r2_ridge_scaled, 'lasso_cv':r2_lasso_scaled,},index=['CV R2'])\n",
    "\n",
    "r2_results.loc['Test R2', :] =[r2_score(y_test,lr_scaled.predict(X_test)),\n",
    "                                r2_score(y_test,ridge_cv_scaled.predict(X_test)),\n",
    "                                r2_score(y_test,lasso_cv_scaled.predict(X_test))]\n",
    "r2_results.loc['lambda','lr']=0\n",
    "r2_results.loc['lambda','ridge_cv']=ridge_cv_scaled.alpha_\n",
    "r2_results.loc['lambda','lasso_cv']=lasso_cv_scaled.alpha_\n",
    "r2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34f70a",
   "metadata": {},
   "source": [
    "Los resultados no han mejorado mucho. Tal vez la inclusión de variables categóricas ayude.\n",
    "\n",
    "Tenemos dos variables categóricas. País y estado. Aplicaremos un One Hot encoding para poder añadirlas al resto de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4018a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_preprocessing(X, y,scaler=None):\n",
    "    print('Original shape:{}'.format(X.shape))\n",
    "    categorical_columns =X.dtypes[X.dtypes == 'category'].index.values\n",
    "    numerical_columns = [c for c in X.columns if c not in categorical_columns]\n",
    "    \n",
    "    # Escalamos las variables numericas\n",
    "    if scaler is None: \n",
    "        # Generamos el scaler cuando los datos son los de entrenamiento\n",
    "        scaler = MinMaxScaler()\n",
    "        X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "    else: \n",
    "        X[numerical_columns] = scaler.transform(X[numerical_columns])\n",
    "    \n",
    "    X = pd.get_dummies(X, columns=categorical_columns, prefix=categorical_columns, dtype=int)\n",
    "    \n",
    "    # Eliminamos los valores perdidos\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('New shape:{}'.format(X.shape))\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, y_train, scaler = categorical_preprocessing(X_train,y_train)\n",
    "X_test, y_test, _ = categorical_preprocessing(X_test,y_test,scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2eaff7",
   "metadata": {},
   "source": [
    "El incluir esta información mejora los resultados, tanto en validación cruzada como en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ea148",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_one_hot = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "r2_lr_one_hot_test = lr_one_hot.score(X_test, y_test)\n",
    "r2_lr_one_hot_cv = np.mean(cross_val_score(lr_one_hot, X_train, y_train, cv=10, scoring='r2'))\n",
    "\n",
    "print('Test R2 score: {}\\nCross-Validation R2 score: {}'.format(r2_lr_one_hot_test, r2_lr_one_hot_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1a4ea",
   "metadata": {},
   "source": [
    "El introducir las variables categóricas ha mejorado los resultados, pero podemos ver que ha afectado mucho a los pesos de nuestro modelo.\n",
    "\n",
    "También podemos ver en los pesos de nuestro modelo que algo falla, ya que hay diferencias entre los rangos de peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d499d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(pd.DataFrame({'lr OHE': lr_one_hot.coef_}).T, cmap=\"seismic\", center=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(lr_one_hot.coef_, bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02bbbf",
   "metadata": {},
   "source": [
    "Si comprobamos cómo se ven nuestros datos, veremos que tenemos una matriz muy dispersa, que es de esperar con el OHE. Esto puede ser problemático a la hora de realizar cálculos numéricos al calcular la SVD de la matriz y ser el culpable de tener pesos que sean bastante grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10394126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8));\n",
    "sns.heatmap(X_test.to_numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facccb18",
   "metadata": {},
   "source": [
    "Para corregir los pesos podemos aplicar regularización. Veamos cómo se comportan nuestros modelos regularizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faee252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_one_hot = RidgeCV(alphas=lambdas, cv=10).fit(X_train, y_train)\n",
    "\n",
    "r2_ridge_one_hot_test = ridge_cv_one_hot.score(X_test,y_test)\n",
    "r2_ridge_one_hot_cv = np.mean(cross_val_score(ridge_cv_one_hot, X_train, y_train, cv=10, scoring='r2'))\n",
    "\n",
    "lasso_cv_one_hot = LassoCV(alphas=lambdas, cv=10).fit(X_train, y_train)\n",
    "\n",
    "r2_lasso_one_hot_test = lasso_cv_one_hot.score(X_test,y_test)\n",
    "r2_lasso_one_hot_cv = np.mean(cross_val_score(lasso_cv_one_hot, X_train, y_train, cv=10, scoring='r2'))\n",
    "\n",
    "weights = pd.DataFrame(\n",
    "    {\n",
    "        'lr_one_hot': lr_one_hot.coef_,\n",
    "        'ridge_cv_one_hot': ridge_cv_one_hot.coef_,\n",
    "        'lasso_cv_one_hot': lasso_cv_one_hot.coef_\n",
    "    },\n",
    "    index=X_train.columns)\n",
    "\n",
    "for column in weights.columns:\n",
    "    fig= plt.figure(figsize=(20,1))\n",
    "    ax=sns.heatmap(weights[[column]].T, cmap=\"seismic\", center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a2014e",
   "metadata": {},
   "source": [
    "Estas son las distribuciones de los pesos de nuestros modelos regularizados. Podemos ver que tanto Ridge como LASSO tienen pesos más razonables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24733de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(ridge_cv_one_hot.coef_, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92767fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(lasso_cv_one_hot.coef_, bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c8caa",
   "metadata": {},
   "source": [
    "Podemos ver tambien que muchos pesos en nuestros modelos son cero o cercanos a cero, pero LASSO tiene muchos más. Esto es de esperar, ya que LASSO tiende a hacer que los pesos sean exactamente cero, mientras que Ridge solo los reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Pesos cercanos a cero en la regresión lineal sin regularización: {np.isclose(lr_one_hot.coef_, np.zeros(lr_one_hot.coef_.shape)).sum()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Pesos IGUAL a cero en la regresión lineal sin regularización: {(lr_one_hot.coef_==0).sum()}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Pesos cercanos a cero en la regresión Ridge: {np.isclose(ridge_cv_one_hot.coef_, np.zeros(ridge_cv_one_hot.coef_.shape)).sum()}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Pesos IGUAL a cero en la regresión Ridge: {(ridge_cv_one_hot.coef_==0).sum()}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Pesos cercanos a cero en la regresión LASSO: {np.isclose(lasso_cv_one_hot.coef_, np.zeros(lasso_cv_one_hot.coef_.shape)).sum()}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Pesos IGUAL a cero en la regresión LASSO: {(lasso_cv_one_hot.coef_==0).sum()}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f31eb",
   "metadata": {},
   "source": [
    "Obtenemos menores pesos en nuestros modelos regularizados. ¿Afectará esto al rendimiento de nuestros modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_results.loc[:, 'lr_one_hot'] =[r2_lr_one_hot_cv, r2_lr_one_hot_test, 0]\n",
    "r2_results.loc[:, 'ridge_cv_one_hot'] =[r2_ridge_one_hot_cv, r2_ridge_one_hot_test, ridge_cv_one_hot.alpha_]\n",
    "r2_results.loc[:, 'lasso_cv_one_hot'] =[r2_lasso_one_hot_cv, r2_lasso_one_hot_test, lasso_cv_one_hot.alpha_]\n",
    "r2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437b602",
   "metadata": {},
   "source": [
    "Podemos ver en nuestras métricas de cv que la regularización no cambia mucho el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199207a3",
   "metadata": {},
   "source": [
    "## SECCIÓN 7: Selección del modelo\n",
    "\n",
    "Ahora usamos el R^2 de validación cruzada para elegir el mejor modelo y comprobaremos sobre especialización con el conjunto de test.\n",
    "\n",
    "Según nuestras métricas de validación, el mejor modelo, marginalmente, es ridge_cv usando las variables categoricas con una lambda de 0,001 utilizada con el conjunto de datos estandarizados con variables categóricas. Si consideramos la simplicidad del modelo, podríamos elegir LASSO con lambda=1e-4, que tiene un rendimiento similar y algunos pesos menos.\n",
    "\n",
    "Podemos ver que el rendimiento en test es similar al de validación cruzada, lo que indica que no hay sobreajuste en el modelo.\n",
    "\n",
    "**Normalmente, antes de probar el \"método ganador\" lo voleríamos a ajustar con todos los datos de entrenamiento; el método RidgeCV hace esto de forma predeterminada para nosotros, por lo que no es necesario que lo hagamos aquí.**\n",
    "\n",
    "Ahora podemos comprobar con los datos de test los residuos y su distribución y ver como se comparan los resultados predichos con los reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tes_predicted = ridge_cv_one_hot.predict(X_test)\n",
    "r2_ridge = ridge_cv_one_hot.score(X_test,y_test)\n",
    "\n",
    "print('Mean sqared error with test data: {}'.format(mean_squared_error(y_test,y_tes_predicted)))\n",
    "print('R2 score with test data: {}'.format(r2_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981a766",
   "metadata": {},
   "source": [
    "Podemos ver que hay un ajuste casi perfecto en los datos de test, lo que indica que nuestro modelo es bueno y no hay sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "visualizer = prediction_error(ridge_cv_one_hot, X_test, y_test, is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a37a02",
   "metadata": {},
   "source": [
    "En la distribución de los residuos podemos observar que el ajuste sobre los cuantiles teóricos es peor que en el modelo inicial (no es una linea recta). Ademas los residuos no son gausianos y tienen una distribucion aun mas extraña que en la regresión anterior.\n",
    "\n",
    "Esto nos puede indicar varias cosas:\n",
    "\n",
    "- puede que el ruido de los datos no sea realmente gausiano y por lo tanto que merezca la pena probar otros modelos alternativos\n",
    "- puede que no todos los ejemplos provengan del mismo proceso, basicamente intervienen otros factores que son relevantes para algunas muestras que hacen que se comporten diferente\n",
    "- puede que las muestras no sean realmente independientes, por lo que debemos usar un modelo diferente que lo tenga en cuenta\n",
    "- puede que sea una combinacion de todo lo anterior ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8));\n",
    "viz = residuals_plot(ridge_cv_one_hot, X_train, y_train, X_test, y_test, is_fitted=True, qqplot=True, hist=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Running time {timedelta(seconds=(time() - init_time))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
